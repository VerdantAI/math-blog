{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f57b506f",
   "metadata": {},
   "source": [
    "# LNN Scratchpad\n",
    "\n",
    "Here I'll be messing with the [LNN Library](https://github.com/IBM/LNN) from IBM.  I want to recreate some [SWI](https://www.swi-prolog.org/) Prolog style queries as well work with their paradigm.  Hopefully this will be slightly useful to others playing with the library and, of course, to myself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823e58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c1f4e",
   "metadata": {},
   "source": [
    "## Socrates \n",
    "\n",
    "He's a man baby, and that makes him mortal.  In prolog this is pretty straightforward. In Prolog, the predicates are \"backward\" to me.\n",
    "\n",
    "Nota bene: I understand the modern idiom is to use \"human\", but later on I want to mess with more predicates so I'm sticking with `man` for the moment.  Yay to trans rights, NB-rights, LGTQIA rights AND to concise coding.  Ain't about that right now.\n",
    "\n",
    "You will need a [db](db.pl) file to load with rules in the standard `swipl` fashion and I won't fight that shit.\n",
    "\n",
    "\n",
    "```\n",
    "> [db].\n",
    "True\n",
    "\n",
    "mortal(socrates).\n",
    "True\n",
    "```\n",
    "\n",
    "The LNN library is a bit more verbose. Also, they don't seem to have settled on a coding style guide yet, so I'm using the one from the [API documentation](https://ibm.github.io/LNN/usage.html) and not the [Tutorials](https://github.com/IBM/LNN/tree/master/tutorials).  Don't worry if makes 0 sense to you right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9638652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************************************************************\n",
      "                                LNN Model\n",
      "\n",
      "OPEN Exists: (∃0, Mortal(0))                                TRUE (1.0, 1.0)\n",
      "\n",
      "AXIOM ForAll: (∀0, (Man(0) → Mortal(0)))                    TRUE (1.0, 1.0)\n",
      "\n",
      "OPEN Implies: (Man(0) → Mortal(0)) \n",
      "'Socrates'                                                  TRUE (1.0, 1.0)\n",
      "\n",
      "OPEN Predicate: Mortal \n",
      "'Socrates'                                                  TRUE (1.0, 1.0)\n",
      "\n",
      "OPEN Predicate: Man \n",
      "'Socrates'                                                  TRUE (1.0, 1.0)\n",
      "\n",
      "***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = lnn.Model()\n",
    "\n",
    "# Create variables. Here I follow the Prolog convention of capitals, they like lowercase\n",
    "X = lnn.Variable('X')\n",
    "\n",
    "# Create some Predicates (has variables).\n",
    "Man, Mortal = lnn.Predicates('Man', 'Mortal')\n",
    "\n",
    "# Axioms\n",
    "Men_Are_Mortal = lnn.ForAll(X, lnn.Implies(Man(X), Mortal(X)))\n",
    "\n",
    "# What we want to ask\n",
    "who_dies = lnn.Exists(X, Mortal(X))\n",
    "\n",
    "# Add knowledge to the model\n",
    "model.add_knowledge(Man, Mortal, Men_Are_Mortal, who_dies)\n",
    "\n",
    "# Now add data about particular objects / records / people\n",
    "# Note this is classical logic, so the truth is basically just \"TRUE\" or \"FALSE\"\n",
    "model.add_data({\n",
    "    Man: {'Socrates': lnn.Fact.TRUE}\n",
    "})\n",
    "\n",
    "# RUN THAT BABY!!\n",
    "model.infer()\n",
    "\n",
    "# SHOW ME THE MONEY!!\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f9ba8",
   "metadata": {},
   "source": [
    "So the model agrees that Socrates is mortal and we've re-created the Prolog statements.  Now let's check out why this is so much more verbose than Prolog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2425bb59",
   "metadata": {},
   "source": [
    "## Socrates Is Fluid\n",
    "\n",
    "Now, I'm not here to teach you anything about [Real Valued Logic](https://en.wikipedia.org/wiki/%C5%81ukasiewicz_logic) other than it's a pretty integral part of [Neuro Symbolic Artificial Intelligence](https://en.wikipedia.org/wiki/Neuro-symbolic_AI), which happens to be my jam right now.  The idea is we can assign confidence to various kinda truthy statements, which means  *FUCK YEAH PROBABILITY THEORY*.  Get yourself a cup of coffee and a copy of [Durrett](https://bookshop.org/p/books/probability-theory-and-examples-rick-durrett/12965062?ean=9781108473682), super fun shit.\n",
    "\n",
    "Now we let Socrates have his/her/their own identity.  Run the whole thing again to keep the variables clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d5f69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************************************************************\n",
      "                                LNN Model\n",
      "\n",
      "OPEN Exists: (∃0, Mortal(0))                       APPROX_UNKNOWN (0.4, 1.0)\n",
      "\n",
      "AXIOM ForAll: (∀0, (Man(0) → Mortal(0)))                    TRUE (1.0, 1.0)\n",
      "\n",
      "OPEN Implies: (Man(0) → Mortal(0)) \n",
      "'Socrates'                                                  TRUE (1.0, 1.0)\n",
      "\n",
      "OPEN Predicate: Mortal \n",
      "'Socrates'                                         APPROX_UNKNOWN (0.4, 1.0)\n",
      "\n",
      "OPEN Predicate: Man \n",
      "'Socrates'                                         APPROX_UNKNOWN (0.4, 0.7)\n",
      "\n",
      "***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = lnn.Model()\n",
    "\n",
    "# Create variables. Here I follow the Prolog convention of capitals, they like lowercase\n",
    "X = lnn.Variable('X')\n",
    "\n",
    "# Create some Predicates (has variables).\n",
    "Man, Mortal = lnn.Predicates('Man', 'Mortal')\n",
    "\n",
    "# Axioms\n",
    "Men_Are_Mortal = lnn.ForAll(X, lnn.Implies(Man(X), Mortal(X)))\n",
    "\n",
    "# What we want to ask\n",
    "who_dies = lnn.Exists(X, Mortal(X))\n",
    "\n",
    "# Add knowledge to the model\n",
    "model.add_knowledge(Man, Mortal, Men_Are_Mortal, who_dies)\n",
    "\n",
    "# Now add data about particular objects / records / people\n",
    "model.add_data({\n",
    "    Man: {'Socrates': (0.4, 0.7)}\n",
    "})\n",
    "\n",
    "# RUN THAT BABY!!\n",
    "model.infer()\n",
    "\n",
    "# SHOW ME THE MONEY!!\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daefe5d",
   "metadata": {},
   "source": [
    "So now Socrates is mortal if he is a Man, which he is questioning.  We don't have an answer if Socrates is not a Man, because we don't know if Women are mortal yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f52f13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************************************************************\n",
      "                                LNN Model\n",
      "\n",
      "OPEN Exists: (∃0, Mortal(0))                                TRUE (1.0, 1.0)\n",
      "\n",
      "AXIOM ForAll: (∀0, (Woman(0) → Mortal(0)))                  TRUE (1.0, 1.0)\n",
      "\n",
      "OPEN Implies: (Woman(0) → Mortal(0)) \n",
      "'Socrates'                                                  TRUE (1.0, 1.0)\n",
      "'Plato'                                                     TRUE (1.0, 1.0)\n",
      "\n",
      "AXIOM ForAll: (∀0, (Man(0) → Mortal(0)))                    TRUE (1.0, 1.0)\n",
      "\n",
      "OPEN Implies: (Man(0) → Mortal(0)) \n",
      "'Socrates'                                                  TRUE (1.0, 1.0)\n",
      "'Plato'                                                     TRUE (1.0, 1.0)\n",
      "\n",
      "OPEN Predicate: Mortal \n",
      "'Socrates'                                         APPROX_UNKNOWN (0.4, 1.0)\n",
      "'Plato'                                              APPROX_TRUE (0.8, 1.0)\n",
      "\n",
      "OPEN Predicate: Man \n",
      "'Socrates'                                         APPROX_UNKNOWN (0.4, 0.7)\n",
      "'Plato'                                              APPROX_TRUE (0.8, 1.0)\n",
      "\n",
      "OPEN Predicate: Woman \n",
      "'Socrates'                                         APPROX_UNKNOWN (0.0, 0.5)\n",
      "'Plato'                                                  UNKNOWN (0.0, 1.0)\n",
      "\n",
      "***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = lnn.Model()\n",
    "\n",
    "# Create variables. Here I follow the Prolog convention of capitals, they like lowercase\n",
    "X = lnn.Variable('X')\n",
    "\n",
    "# Create some Predicates (has variables).\n",
    "Woman, Man, Mortal = lnn.Predicates('Woman', 'Man', 'Mortal')\n",
    "\n",
    "# Axioms\n",
    "Men_Are_Mortal = lnn.ForAll(X, lnn.Implies(Man(X), Mortal(X)))\n",
    "Women_Are_Mortal = lnn.ForAll(X, lnn.Implies(Woman(X), Mortal(X)))\n",
    "\n",
    "# What we want to ask\n",
    "who_dies = lnn.Exists(X, Mortal(X))\n",
    "\n",
    "# Add knowledge to the model\n",
    "model.add_knowledge(Woman, Man, Mortal, Men_Are_Mortal, Women_Are_Mortal, who_dies)\n",
    "\n",
    "# Now add data about particular objects / records / people\n",
    "model.add_data({\n",
    "    Man: {'Socrates': (0.4, 0.7), 'Plato': (0.8, 1.0)},\n",
    "    Woman: {'Socrates': (0, 0.5)}\n",
    "})\n",
    "\n",
    "# RUN THAT BABY!!\n",
    "model.infer()\n",
    "\n",
    "# SHOW ME THE MONEY!!\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b595ed0",
   "metadata": {},
   "source": [
    "If you ask me, this is pretty fun.  Socrates stil has a lot of questioning to do before he comes out as a `Mortal`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a411bb1",
   "metadata": {},
   "source": [
    "# Short Skirt, Long Jacket\n",
    "\n",
    "Turns out some men are just too picky for their own damn good, and the guys from Cake made a nice [satire](https://www.youtube.com/watch?v=X5KmB8Laemg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353c0274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************************************************************\n",
      "                                LNN Model\n",
      "\n",
      "OPEN And: (FingernailsShineLikeJustice(0) ∧ LongSkirt(1)) \n",
      "\n",
      "OPEN Predicate: LongSkirt \n",
      "\n",
      "OPEN Predicate: FingernailsShineLikeJustice \n",
      "'Alice'                                                     TRUE (1.0, 1.0)\n",
      "\n",
      "***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = lnn.Model()\n",
    "\n",
    "# Create variables. Here I follow the Prolog convention of capitals, they like lowercase\n",
    "X = lnn.Variable('X')\n",
    "\n",
    "\n",
    "FingernailsShineLikeJustice, Skirt = lnn.Predicates(\"FingernailsShineLikeJustice\", \"LongSkirt\")\n",
    "\n",
    "# Axioms\n",
    "\n",
    "# Predicates direct to model?  Seems easier\n",
    "model.add_knowledge(\n",
    "    FingernailsShineLikeJustice, LongSkirt,\n",
    "    lnn.And(FingernailsShineLikeJustice, LongSkirt)\n",
    ")\n",
    "\n",
    "# Add some candidates (data)\n",
    "model.add_data({\n",
    "    FingernailsShineLikeJustice: {'Alice': lnn.Fact.TRUE}\n",
    "})\n",
    "\n",
    "# Run that Baby!\n",
    "model.infer()\n",
    "\n",
    "# SHOW ME THE MONEY!\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f5eb4",
   "metadata": {},
   "source": [
    "My life is going to be so much easier if we can get the models built by marshalling JSON.  I'm sure there is a way, but grrr.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c0001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ad4db4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'propositional'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 21\u001b[0m\n\u001b[1;32m      7\u001b[0m preds \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFingernailsShineLikeJustice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShortSkirt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m ]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#for p in preds:\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#    globals()[p] = lnn.Predicate(p)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Predicates direct to model?  Seems easier\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39madd_knowledge(\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;241m*\u001b[39m[lnn\u001b[38;5;241m.\u001b[39mPredicate(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m preds],\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mlnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAnd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFingernailsShineLikeJustice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mShortSkirt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Add some candidates (data)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39madd_data({\n\u001b[1;32m     26\u001b[0m     FingernailsShineLikeJustice: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlice\u001b[39m\u001b[38;5;124m'\u001b[39m: lnn\u001b[38;5;241m.\u001b[39mFact\u001b[38;5;241m.\u001b[39mTRUE}\n\u001b[1;32m     27\u001b[0m })\n",
      "File \u001b[0;32m~/src/math-blog/nesy/env/lib/python3.11/site-packages/lnn/symbolic/logic/n_ary_neuron.py:61\u001b[0m, in \u001b[0;36mAnd.__init__\u001b[0;34m(self, *formula, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwds\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnective_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_connective_str(\n\u001b[1;32m     59\u001b[0m     kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     60\u001b[0m )\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/math-blog/nesy/env/lib/python3.11/site-packages/lnn/symbolic/logic/n_ary_neuron.py:21\u001b[0m, in \u001b[0;36m_NAryNeuron.__init__\u001b[0;34m(self, *formula, **kwds)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mformula, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mformula\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/math-blog/nesy/env/lib/python3.11/site-packages/lnn/symbolic/logic/connective_neuron.py:38\u001b[0m, in \u001b[0;36m_ConnectiveNeuron.__init__\u001b[0;34m(self, *formula, **kwds)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mformula, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     kwds\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marity)\n\u001b[1;32m     40\u001b[0m     kwds\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpropositional\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropositional)\n",
      "File \u001b[0;32m~/src/math-blog/nesy/env/lib/python3.11/site-packages/lnn/symbolic/logic/connective_formula.py:17\u001b[0m, in \u001b[0;36m_ConnectiveFormula.__init__\u001b[0;34m(self, *formula, **kwds)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mformula: Formula, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/math-blog/nesy/env/lib/python3.11/site-packages/lnn/symbolic/logic/formula.py:61\u001b[0m, in \u001b[0;36mFormula.__init__\u001b[0;34m(self, name, arity, *formulae, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropositional: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpropositional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables: Tuple[Variable, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inherit_from_subformulae\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mformulae\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# formula naming\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _isinstance(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_LeafFormula\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/src/math-blog/nesy/env/lib/python3.11/site-packages/lnn/symbolic/logic/formula.py:1007\u001b[0m, in \u001b[0;36mFormula._inherit_from_subformulae\u001b[0;34m(self, *subformula)\u001b[0m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperands\u001b[38;5;241m.\u001b[39mappend(f[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;66;03m# automatically inherit variable remapping from `uncalled` operands\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m#   for higher level connective formulae:\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;66;03m#     ```\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropositional\u001b[49m:\n\u001b[1;32m   1008\u001b[0m         _var_remap[slot] \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39munique_vars\n\u001b[1;32m   1009\u001b[0m         _operand_vars[slot] \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39munique_vars\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'propositional'"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = lnn.Model()\n",
    "\n",
    "# Create variables. Here I follow the Prolog convention of capitals, they like lowercase\n",
    "X = lnn.Variable('X')\n",
    "\n",
    "preds = [\n",
    "    'FingernailsShineLikeJustice', 'ShortSkirt'\n",
    "]\n",
    "\n",
    "\n",
    "# Axioms\n",
    "\n",
    "# Predicates direct to model?  Seems easier\n",
    "# I just learned the *[...] will unlist the array \n",
    "model.add_knowledge(\n",
    "    *[lnn.Predicate(p) for p in preds],\n",
    "    lnn.And('FingernailsShineLikeJustice', 'ShortSkirt')\n",
    ")\n",
    "\n",
    "# Add some candidates (data)\n",
    "model.add_data({\n",
    "    FingernailsShineLikeJustice: {'Alice': lnn.Fact.TRUE}\n",
    "})\n",
    "\n",
    "# Run that Baby!\n",
    "model.infer()\n",
    "\n",
    "# SHOW ME THE MONEY!\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eddba8d",
   "metadata": {},
   "source": [
    "# Up & Down\n",
    "\n",
    "I need to get a handle on the `upward()` and `downward()` of it all.  [This notebook](https://github.com/IBM/LNN/blob/master/tutorials/Chapter%201%20-%20Reasoning/0.%20Propositional%20Logic.ipynb) introduces the idea, but does so in a traditional FOL perspective.  I want to internalize it from an AI perspective.  The notion of [modus ponens](https://en.wikipedia.org/wiki/Modus_ponens) seems to be something they are excited about.  Now, I don't doubt this is thrilling, but it's not real to me for building agents.\n",
    "\n",
    "The example in the [second notebook](https://github.com/IBM/LNN/blob/master/tutorials/Chapter%201%20-%20Reasoning/1.%20Propositional%20Bounds.ipynb) is nice.  They have two nodes that afe facts and a relation that is a higher level node.  In the `up` example they have truth values for the nodes and get a prediction for the relation.  In the `down` example they provide truth values for one node and the relation, then try to find the truth value for the second node.\n",
    "\n",
    "Let's do a simplistic example.  First, let's see our confidence Cthulu has both a short skirt AND a long jacket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab36a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN And: (ShortSkirt ∧ LongJacket)                APPROX_UNKNOWN (0.5, 1.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Polluting the global namespace, restart the notebook\n",
    "# Predicates\n",
    "ShortSkirt, LongJacket = lnn.Propositions(\"ShortSkirt\", \"LongJacket\")\n",
    "AND = lnn.And(ShortSkirt, LongJacket)\n",
    "\n",
    "# Data\n",
    "# We know the facts of her wardrobe\n",
    "ShortSkirt.add_data((0.7, 1.0))\n",
    "LongJacket.add_data((0.8, 1.0))\n",
    "\n",
    "# Reasoning\n",
    "AND.upward()\n",
    "AND.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4c042",
   "metadata": {},
   "source": [
    "Now we want to infer whether she has a Long Jacket.  This is starting to make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4e0fad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN Proposition: LongJacket                         APPROX_TRUE (0.6, 1.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Polluting the global namespace, restart the notebook\n",
    "# Predicates\n",
    "ShortSkirt, LongJacket = lnn.Propositions(\"ShortSkirt\", \"LongJacket\")\n",
    "AND = lnn.And(ShortSkirt, LongJacket)\n",
    "\n",
    "# Data\n",
    "# We have ground for ShortSkit and \"AND\"\n",
    "ShortSkirt.add_data((0.7, 1.0))\n",
    "AND.add_data((0.6, 1.0))\n",
    "\n",
    "# Reasoning\n",
    "AND.downward()\n",
    "LongJacket.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb9425",
   "metadata": {},
   "source": [
    "Mess with giving all the values?  Let's just check, what's the worst that can happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae2d08c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN And: (ShortSkirt ∧ LongJacket)                  APPROX_TRUE (0.6, 1.0)\n",
      "\n",
      "OPEN Proposition: ShortSkirt                         APPROX_TRUE (0.7, 1.0)\n",
      "\n",
      "OPEN Proposition: LongJacket                         APPROX_TRUE (0.8, 1.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Polluting the global namespace, restart the notebook\n",
    "# Predicates\n",
    "ShortSkirt, LongJacket = lnn.Propositions(\"ShortSkirt\", \"LongJacket\")\n",
    "AND = lnn.And(ShortSkirt, LongJacket)\n",
    "\n",
    "# Data\n",
    "# We have ground for ShortSkit and \"AND\"\n",
    "ShortSkirt.add_data((0.7, 1.0))\n",
    "LongJacket.add_data((0.8, 1.0))\n",
    "AND.add_data((0.6, 1.0))\n",
    "\n",
    "# Reasoning\n",
    "AND.upward()\n",
    "AND.print()\n",
    "ShortSkirt.print()\n",
    "LongJacket.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f3ee468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN And: (ShortSkirt ∧ LongJacket)                  APPROX_TRUE (0.6, 1.0)\n",
      "\n",
      "OPEN Proposition: ShortSkirt                         APPROX_TRUE (0.7, 1.0)\n",
      "\n",
      "OPEN Proposition: LongJacket                         APPROX_TRUE (0.8, 1.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Polluting the global namespace, restart the notebook\n",
    "# Predicates\n",
    "ShortSkirt, LongJacket = lnn.Propositions(\"ShortSkirt\", \"LongJacket\")\n",
    "AND = lnn.And(ShortSkirt, LongJacket)\n",
    "\n",
    "# Data\n",
    "# We have ground for ShortSkit and \"AND\"\n",
    "ShortSkirt.add_data((0.7, 1.0))\n",
    "LongJacket.add_data((0.8, 1.0))\n",
    "AND.add_data((0.6, 1.0))\n",
    "\n",
    "# Reasoning\n",
    "AND.downward()\n",
    "AND.print()\n",
    "ShortSkirt.print()\n",
    "LongJacket.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674cdcaf",
   "metadata": {},
   "source": [
    "Looks to me like they just spit back the given models.  For exhaustion, let's try this in a `model` context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3f50008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN And: (ShortSkirt ∧ LongJacket)                APPROX_UNKNOWN (0.5, 1.0)\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fact expected from [lnn.Fact, lnn.World, tuple] received dict {'Alice': (0.7, 1.0)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 27\u001b[0m\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39madd_knowledge(\n\u001b[1;32m     21\u001b[0m     ShortSkirt, LongJacket, AND\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Data\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# We have ground for ShortSkit and \"AND\"\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mShortSkirt\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAlice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Run that Baby!\u001b[39;00m\n\u001b[1;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39minfer()\n",
      "File \u001b[0;32m~/src/math-blog/nesy/env/lib/python3.11/site-packages/lnn/model.py:352\u001b[0m, in \u001b[0;36mModel.add_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    350\u001b[0m _exceptions\u001b[38;5;241m.\u001b[39mAssertFormulaInModel(\u001b[38;5;28mself\u001b[39m, formula)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m formula\u001b[38;5;241m.\u001b[39mpropositional:\n\u001b[0;32m--> 352\u001b[0m     \u001b[43m_exceptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAssertBounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfact\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     _exceptions\u001b[38;5;241m.\u001b[39mAssertFOLFacts(fact)\n",
      "File \u001b[0;32m~/src/math-blog/nesy/env/lib/python3.11/site-packages/lnn/_exceptions.py:117\u001b[0m, in \u001b[0;36mAssertBounds.__init__\u001b[0;34m(self, bounds)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, bounds):\n\u001b[0;32m--> 117\u001b[0m     \u001b[43mAssertBoundsType\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     AssertBoundsLen(bounds)\n\u001b[1;32m    119\u001b[0m     AssertBoundsInputs(bounds)\n",
      "File \u001b[0;32m~/src/math-blog/nesy/env/lib/python3.11/site-packages/lnn/_exceptions.py:64\u001b[0m, in \u001b[0;36mAssertBoundsType.__init__\u001b[0;34m(self, bounds)\u001b[0m\n\u001b[1;32m     62\u001b[0m options \u001b[38;5;241m=\u001b[39m [Fact, World, \u001b[38;5;28mtuple\u001b[39m]\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(bounds) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m options:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfact expected from [lnn.Fact, lnn.World, tuple] \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceived \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbounds\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbounds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: fact expected from [lnn.Fact, lnn.World, tuple] received dict {'Alice': (0.7, 1.0)}"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = lnn.Model()\n",
    "\n",
    "# Variables\n",
    "X = lnn.Variable('X')\n",
    "\n",
    "# Polluting the global namespace, restart the notebook\n",
    "# Predicates\n",
    "ShortSkirt, LongJacket = lnn.Propositions(\"ShortSkirt\", \"LongJacket\")\n",
    "AND = lnn.And(ShortSkirt, LongJacket)\n",
    "# think we need direction before we add to the model\n",
    "AND.add_data((0.5, 1.0))\n",
    "\n",
    "\n",
    "AND.downward()\n",
    "AND.print()\n",
    "\n",
    "\n",
    "# Add predictes to model\n",
    "model.add_knowledge(\n",
    "    ShortSkirt, LongJacket, AND\n",
    ")\n",
    "\n",
    "\n",
    "# Data\n",
    "# We have ground for ShortSkit and \"AND\"\n",
    "model.add_data({\n",
    "    ShortSkirt : {\"Alice\": (0.7, 1.0)}\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Run that Baby!\n",
    "model.infer()\n",
    "\n",
    "# SHOW ME THE MONEY!\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd10e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
